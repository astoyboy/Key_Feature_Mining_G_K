{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/all/')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = df.drop('material_id', axis=1)\n",
    "X = data_set.drop('taeget',axis=1)\n",
    "y = data_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_params = {\n",
    "    'n_estimators': 800,        \n",
    "    'max_depth': 20,            \n",
    "    'min_samples_split': 4,    \n",
    "    'min_samples_leaf': 2,     \n",
    "}\n",
    "\n",
    "etr_params = {'max_features': 1.0,\n",
    "    'min_samples_leaf': 1, \n",
    "    'min_samples_split': 2,\n",
    "    'n_estimators': 300\n",
    "}\n",
    "\n",
    "gbr_params = { 'learning_rate': 0.1,\n",
    "    'loss': 'squared_error',\n",
    "    'max_depth': 7,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 2,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'n_estimators':800\n",
    " }\n",
    "\n",
    "lgbr_params = {'n_estimators':2000,\n",
    "    'num_leaves': 35\n",
    "}\n",
    "\n",
    "xgbr_params = {\n",
    "    'colsample_bytree': 1.0,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 7,\n",
    "    'n_estimators': 2000,\n",
    "    'subsample': 1.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [\n",
    "    ('RFR', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "        ('rfr', RandomForestRegressor(**rfr_params))\n",
    "    ])),\n",
    "    \n",
    "    ('ETR', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "        ('etr', ExtraTreesRegressor(**etr_params))\n",
    "    ])),\n",
    "    \n",
    "    ('GBR', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "        ('gbr', GradientBoostingRegressor(**gbr_params))\n",
    "    ])),\n",
    "    \n",
    "    ('LGBM', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "        ('lgbm', LGBMRegressor(**lgbr_params))\n",
    "    ])),\n",
    "    \n",
    "    ('XGBoost', Pipeline([\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "        ('xgboost', XGBRegressor(**xgbr_params))\n",
    "    ]))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shear Modulus(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, pipeline in pipelines:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"训练模型: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=79)\n",
    "    \n",
    "    scores = []\n",
    "    mae_scores = []\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        score = pipeline.score(X_test, y_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        scores.append(score)\n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "    \n",
    "    print(f\"{model_name} - R^2 scores:\", scores)\n",
    "    print(f\"{model_name} - Mean R^2 score:\", sum(scores) / len(scores))\n",
    "    print(f\"{model_name} - MAE scores:\", mae_scores)\n",
    "    print(f\"{model_name} - Mean MAE:\", sum(mae_scores) / len(mae_scores))\n",
    "    print(f\"{model_name} - RMSE scores:\", rmse_scores)\n",
    "    print(f\"{model_name} - Mean RMSE:\", sum(rmse_scores) / len(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bullk Modulus(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, pipeline in pipelines:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"训练模型: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=35)\n",
    "    \n",
    "    scores = []\n",
    "    mae_scores = []\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        score = pipeline.score(X_test, y_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        scores.append(score)\n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "    \n",
    "    print(f\"{model_name} - R^2 scores:\", scores)\n",
    "    print(f\"{model_name} - Mean R^2 score:\", sum(scores) / len(scores))\n",
    "    print(f\"{model_name} - MAE scores:\", mae_scores)\n",
    "    print(f\"{model_name} - Mean MAE:\", sum(mae_scores) / len(mae_scores))\n",
    "    print(f\"{model_name} - RMSE scores:\", rmse_scores)\n",
    "    print(f\"{model_name} - Mean RMSE:\", sum(rmse_scores) / len(rmse_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
