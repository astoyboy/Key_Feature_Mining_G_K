{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c44e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3722d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/FP/\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7969e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = df.drop('material_id', axis=1)\n",
    "X = data_set.drop('GVRH',axis=1)\n",
    "y = data_set['GVRH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313586df",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd569f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pipeline = LGBMRegressor(n_estimators=1800,num_leaves=31)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 68)\n",
    "lgbm_pipeline.fit(X_train, y_train)\n",
    "print('test R2 = ' + str(lgbm_pipeline.score(X_test, y_test)))\n",
    "print('test MAE = ' + str(mean_absolute_error(y_true = y_test, y_pred = lgbm_pipeline.predict(X_test))))\n",
    "print('test RMSE = ' + str(np.sqrt(mean_squared_error(y_true = y_test, y_pred = lgbm_pipeline.predict(X_test)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4effc047",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importances = lgbm_pipeline.feature_importances_\n",
    "\n",
    "feature_importance_df1 = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "feature_importance_df1['Importance'] /= feature_importance_df1['Importance'].sum()\n",
    "\n",
    "feature_importance_df1 = feature_importance_df1.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_n = 100\n",
    "top_features1 = feature_importance_df1.head(top_n)\n",
    "\n",
    "others_importance = feature_importance_df1.tail(len(feature_importance_df1) - top_n)['Importance'].sum()\n",
    "\n",
    "others_row = pd.DataFrame({'Feature': ['others'], 'Importance': [others_importance]})\n",
    "top_features1 = pd.concat([top_features1, others_row], ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.barh(top_features1['Feature'], top_features1['Importance'], color='skyblue')\n",
    "plt.xlabel('Normalized Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "for bar in bars:\n",
    "    plt.text(\n",
    "        bar.get_width() + 0.001, \n",
    "        bar.get_y() + bar.get_height() / 2, \n",
    "        f'{bar.get_width():.4f}', \n",
    "        va='center', \n",
    "        fontsize=12\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a14ba82",
   "metadata": {},
   "source": [
    "#### Get the top 100 features ranked by feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106683c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = lgbm_pipeline.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns,'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
    "top_n = 100\n",
    "top_features = feature_importance_df.head(top_n)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))  \n",
    "plt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance', fontsize=14)  \n",
    "plt.ylabel('Feature', fontsize=14)  \n",
    "plt.title(f'Top {top_n} Feature Importance', fontsize=16)  \n",
    "plt.xticks(fontsize=12)  \n",
    "plt.yticks(fontsize=12)  \n",
    "plt.gca().invert_yaxis()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede569ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['GVRH','material_id'],axis=1)\n",
    "y = df['GVRH']\n",
    "X = X[top_features['Feature']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a3089",
   "metadata": {},
   "source": [
    "### Select key features through hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9a118",
   "metadata": {},
   "source": [
    "#### Carry out clustering to select important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr = X.corr().abs()\n",
    "\n",
    "# Check and handle NaN and Inf values\n",
    "corr.fillna(0, inplace=True)\n",
    "\n",
    "# Convert to distance matrix\n",
    "distance_matrix = 1 - corr\n",
    "\n",
    "# Ensure matrix has no non-finite values\n",
    "distance_matrix = np.nan_to_num(distance_matrix, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "\n",
    "# Perform hierarchical clustering using Ward's method\n",
    "linkage_matrix = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Extract clusters\n",
    "threshold = k  # k can be obtained from the paper\n",
    "clusters = fcluster(linkage_matrix, threshold, criterion='distance')\n",
    "\n",
    "selected_features = []\n",
    "for cluster_id in np.unique(clusters):\n",
    "    # Get features in current cluster\n",
    "    cluster_features = corr.columns[clusters == cluster_id]\n",
    "    \n",
    "    # Find importance of these features from feature_importance_df\n",
    "    cluster_importances = feature_importance_df[feature_importance_df['Feature'].isin(cluster_features)]\n",
    "    \n",
    "    # Select feature with highest importance contribution\n",
    "    if not cluster_importances.empty:\n",
    "        # Find feature with highest importance\n",
    "        representative_feature = cluster_importances.loc[cluster_importances['Importance'].idxmax(), 'Feature']\n",
    "        selected_features.append(representative_feature)\n",
    "\n",
    "# Update dataset with selected features\n",
    "X = df[selected_features]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
